# Documenta√ß√£o Completa do Projeto ICMBio
## (Baseada no C√≥digo Real Existente)

## √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Estrutura Real do Projeto](#estrutura-real-do-projeto)
3. [Arquivos Principais - Como Funcionam](#arquivos-principais---como-funcionam)
4. [Dataset e Carregamento de Dados](#dataset-e-carregamento-de-dados)
5. [Modelos Implementados](#modelos-implementados)
6. [Sistema de Treinamento](#sistema-de-treinamento)
7. [Infer√™ncia e Teste](#infer√™ncia-e-teste)
8. [Configura√ß√µes Reais](#configura√ß√µes-reais)
9. [Como Executar - Passo Real](#como-executar---passo-real)

## Vis√£o Geral

Este projeto implementa **segmenta√ß√£o sem√¢ntica** para classifica√ß√£o de uso do solo usando redes neurais convolucionais. Foi desenvolvido para o ICMBio e classifica pixels de imagens em **8 classes** distintas de cobertura terrestre.

### Classes do Dataset (Definidas no projeto)
```python
'classes': [
    "Urbano",           # 0 - Vermelho (255, 0, 0)
    "Vegeta√ß√£o Densa",  # 1 - Verde (0, 255, 0)  
    "Sombra",           # 2 - Preto (0, 0, 0)
    "Vegeta√ß√£o Esparsa",# 3 - Amarelo (255, 255, 0)
    "Agricultura",      # 4 - Laranja (255, 165, 0)
    "Rocha",            # 5 - Cinza (128, 128, 128)
    "Solo Exposto",     # 6 - Marrom (139, 69, 19)
    "√Ågua"              # 7 - Azul (0, 0, 255)
]
```

### Tecnologias Utilizadas (Reais)
- **PyTorch**: Framework principal
- **Segmentation Models PyTorch**: Para arquiteturas U-Net, DeepLabV3+
- **Albumentations**: Data augmentation
- **TorchMetrics**: M√©tricas de avalia√ß√£o
- **scikit-image**: Processamento de imagens
- **OpenCV**: Opera√ß√µes de imagem

## Estrutura Real do Projeto

```
icmbio2/
‚îú‚îÄ‚îÄ main.py                    # ‚úÖ Script principal de execu√ß√£o
‚îú‚îÄ‚îÄ trainer.py                 # ‚úÖ Classe Trainer para treinamento/valida√ß√£o/teste
‚îú‚îÄ‚îÄ models.py                  # ‚úÖ Defini√ß√µes de modelos (FCN8s, U-Net factory)
‚îú‚îÄ‚îÄ dataset1.py                # ‚úÖ Dataset com sliding window e augmentation forte
‚îú‚îÄ‚îÄ datasetSlide.py           # ‚úÖ Dataset alternativo mais simples
‚îú‚îÄ‚îÄ inference.py              # ‚úÖ Script para infer√™ncia em produ√ß√£o
‚îú‚îÄ‚îÄ project_utils.py          # ‚úÖ Fun√ß√µes utilit√°rias essenciais
‚îú‚îÄ‚îÄ common.py                 # ‚úÖ Transformadas wavelet (DWT/IWT)
‚îú‚îÄ‚îÄ focal_loss.py             # ‚úÖ Implementa√ß√£o Focal Loss e Class-Balanced Loss
‚îú‚îÄ‚îÄ extra/                    # ‚úÖ Scripts auxiliares existentes
‚îÇ   ‚îú‚îÄ‚îÄ label_change_pixel_color.py  # ‚úÖ Trocar cores dos labels
‚îÇ   ‚îú‚îÄ‚îÄ test_trained.py       # ‚úÖ An√°lise de resultados de teste
‚îÇ   ‚îî‚îÄ‚îÄ weights_calculator.py # ‚úÖ (referenciado) Calcular pesos das classes
‚îî‚îÄ‚îÄ folds/                    # ‚úÖ Divis√£o K-fold dos dados
    ‚îú‚îÄ‚îÄ fold1_images.txt
    ‚îú‚îÄ‚îÄ fold1_labels.txt
    ‚îî‚îÄ‚îÄ ... (fold2-5)
```

## Arquivos Principais - Como Funcionam

### 1. main.py - Orquestrador Principal

**O que realmente faz:**
```python
# Configura√ß√£o de par√¢metros (hardcoded no arquivo)
params = {
    'root_dir': '../../dataset_35/',
    'window_size': (224, 224),
    'bs': 40,                    # Batch size
    'n_classes': 8,
    'maximum_epochs': 999,
    'cache': True,
    'augment': False,            # Controla data augmentation
    
    # Modelo
    'model': {'name': 'unet'},   # Definido na fun√ß√£o build_model()
    
    # Otimizador  
    'optimizer_params': {
        'optimizer': 'ADAM',
        'lr': 1e-3,
        'beta1': 0.9,
        'beta2': 0.999,
        'weight_decay': 0,
        'epsilon': 1e-8,
    },
    
    # Loss function
    'loss': {
        'name': LossFN.TVERSKY,  # Enum definido no pr√≥prio arquivo
        'params': {'weights': 'calculate'}
    },
    
    'patience': 10,              # Para early stopping
}

# Sistema real de carregamento de dados
def load_data_real():
    # Carrega listas de arquivos dos folds
    train_images = []
    for fold_num in [1, 2, 3]:  # 3 folds para treino
        fold_images = pd.read_table(f'folds/fold{fold_num}_images.txt', header=None).values
        train_images.extend([os.path.join(image_dir, f[0]) for f in fold_images])
    
    val_images = pd.read_table('folds/fold4_images.txt', header=None).values
    val_images = [os.path.join(image_dir, f[0]) for f in val_images]
    
    test_images = pd.read_table('folds/fold5_images.txt', header=None).values  
    test_images = [os.path.join(image_dir, f[0]) for f in test_images]

# Loop principal de treinamento (c√≥digo real)
def real_training_loop():
    # C√°lculo autom√°tico de pesos das classes
    weights_calculator_loss(params, train_labels)
    
    # Cria√ß√£o dos datasets
    train_dataset = DatasetIcmbio(train_images, train_labels, None, 
                                 window_size=params['window_size'], 
                                 cache=params['cache'], 
                                 augmentation=params['augment'])
    
    # Sistema de callback para early stopping
    patCB = Callback(patience=params['patience'], min_value=60)
    
    # Loop real de √©pocas
    for epoch in range(trainer.last_epoch+1, params['maximum_epochs']):
        acc_train, f1score_train, mcc_train, iou_train = trainer.train()
        acc_val, f1score_val, mcc_val, iou_val = trainer.validate(stride=64)
        
        # Salvar m√©tricas
        trainer.epoch_acc.append(acc_train)
        trainer.epoch_val_acc.append(acc_val)
        # ... outras m√©tricas
        
        # Plotar m√©tricas automaticamente
        trainer.plot_metrics(params['results_folder'])
        
        # Scheduler step
        if trainer.scheduler is not None:
            trainer.scheduler.step(iou_val)
        
        # Early stopping baseado em IoU
        if patCB.patience_iou_val(iou_val):
            trainer.save(os.path.join(params['results_folder'], 'best_epoch.pth.tar'))
        
        # Parar se atingir paci√™ncia
        if patCB.COUNTER == patCB.PATIENCE:
            print(f"PATIENCE ::: Training Terminated | Best Epoch = {epoch-10}")
            break
```

### 2. trainer.py - N√∫cleo do Sistema

**Classe Trainer completa (c√≥digo real):**

#### Inicializa√ß√£o Real:
```python
class Trainer():
    def __init__(self, net, loader, params, scheduler=True, cbkp=None):
        self.net = net
        self.loader = loader
        self.params = params
        
        # M√©tricas armazenadas (listas reais)
        self.epoch_loss = []
        self.epoch_val_loss = []
        self.epoch_acc = []
        self.epoch_val_acc = []
        self.epoch_f1 = []
        self.epoch_val_f1 = []
        self.epoch_mcc = []
        self.epoch_val_mcc = []
        self.epoch_iou = []
        self.epoch_val_iou = []
        
        # Fun√ß√µes de perda reais dispon√≠veis
        self.CE = nn.CrossEntropyLoss(reduce=None, reduction="none")
        self.FL = FocalLoss(mode='multiclass', alpha=0.5, gamma=2.0, reduction='none')
        self.DI = DiceLoss(mode='multiclass', classes=8, from_logits=True)
        self.JL = JaccardLoss(mode='multiclass', classes=8, from_logits=True)
        self.TV = TverskyLoss(mode='multiclass', classes=8, from_logits=True, alpha=1.0, beta=0.5)
```

#### M√©todo train() Real:
```python
def train(self):
    # M√©tricas TorchMetrics reais
    acc_metric = Accuracy(num_classes=self.params['n_classes'], average='macro', task='multiclass').to(self.device)
    f1_metric = F1Score(num_classes=self.params['n_classes'], average='macro', task='multiclass').to(self.device)
    iou_metric = JaccardIndex(num_classes=self.params['n_classes'], average='macro', task='multiclass').to(self.device)
    mcc_metric = MatthewsCorrCoef(num_classes=self.params['n_classes'], task='multiclass').to(self.device)
    
    self.net.train()
    train_running_loss = 0.0
    pbar = tqdm(self.loader['train'])
    
    for batch_id, (inputs, labels) in enumerate(pbar):
        inputs, labels = self.prepare([inputs, labels])  # Move para GPU
        inputs = inputs[:,:3,:,:]  # Apenas RGB
        
        self.optimizer.zero_grad()
        outputs = self.net(inputs)  # Forward pass
        
        probs = F.softmax(outputs, dim=1)
        labels = labels.long()
        
        # Loss real utilizada (Tversky por padr√£o)
        loss = self.TV(outputs, labels)
        
        loss.backward()
        self.optimizer.step()
        
        # Calcular m√©tricas
        max_values, armax = torch.max(probs.data, 1)
        acc_metric.update(armax, labels)
        f1_metric.update(armax, labels)
        mcc_metric.update(armax, labels)
        iou_metric.update(armax, labels)
        
        # Extrair valores para display
        acc = 100.0 * acc_metric.compute().item()
        f1 = 100.0 * f1_metric.compute().item()
        mcc = 100.0 * mcc_metric.compute().item()
        iou = 100.0 * iou_metric.compute().item()
        train_running_loss += loss.item()
        
        # Progress bar real
        pbar.set_postfix({
            'Epoch': self.last_epoch,
            'Acc': acc,
            'F1': f1,
            'MCC': mcc,
            'IoU': iou,
            'Loss': train_running_loss/(batch_id+1),
        })
        
        self.iter_ += 1
        del(inputs, labels, loss)  # Limpeza de mem√≥ria
    
    return acc, f1, mcc, iou
```

#### Valida√ß√£o com Sliding Window (Real):
```python
def validate(self, stride=32, window_size=(224,224), batch_size=None, all=False):
    val_ld = self.loader.get('val', None)
    input_ids, label_ids, _ = val_ld.dataset.get_dataset()
    
    # Processar cada imagem completa
    for img, gt, gt_e, image_path in tqdm(zip(test_images, test_labels, eroded_labels, input_ids)):
        H, W = img.shape[:2]
        h, w = window_size
        
        # Mapas de acumula√ß√£o para sliding window
        pred = torch.zeros(self.params['n_classes'], H, W).to(self.device)
        count = torch.zeros(H, W).to(self.device)
        
        # Sliding window real
        for x, y, h_patch, w_patch in sliding_window(img, stride, (h, w)):
            patch = img[x:x+h_patch, y:y+w_patch]
            if patch.shape != (h, w):
                continue
                
            patch_tensor = torch.from_numpy(patch).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                out = self.net(patch_tensor)
                out = F.softmax(out, dim=1)
                
            # Acumular predi√ß√µes
            pred[:, x:x+h, y:y+w] += out.squeeze(0)
            count[x:x+h, y:y+w] += 1
        
        # M√©dia das predi√ß√µes sobrepostas
        pred_label = pred / count.unsqueeze(0)
        pred_label = pred_label.argmax(dim=0)
        
        # Atualizar m√©tricas
        acc_metric.update(pred_label, gt_e)
        f1_metric.update(pred_label, gt_e)
        mcc_metric.update(pred_label, gt_e)
        iou_metric.update(pred_label, gt_e)
```

#### Monte Carlo Dropout (Implementado):
```python
def test_mc_dropout(self, mc_runs=25, mc_dropout_rates=None, return_detailed=False):
    """MC Dropout real implementado no c√≥digo"""
    
    # Configurar dropout rates
    if mc_dropout_rates is not None:
        dropout_rates_list = list(mc_dropout_rates)
    else:
        dropout_rates_list = [None] * mc_runs
    
    # Fun√ß√£o para ativar MC dropout
    def set_mc_dropout_mode(model, enable: bool, p: Optional[float] = None):
        model.eval()
        for m in model.modules():
            if isinstance(m, (nn.Dropout, nn.Dropout2d, nn.Dropout3d)):
                if enable:
                    m.train()
                else:
                    m.eval()
                if (p is not None) and hasattr(m, 'p'):
                    m.p = float(p)
    
    # Executar m√∫ltiplas runs
    preds_per_image = [[] for _ in range(n_images)]
    
    for run_idx in range(mc_runs):
        set_mc_dropout_mode(self.net, enable=True, p=dropout_rates_list[run_idx])
        
        # Infer√™ncia normal
        run_predictions = self.predict_all_images()
        
        for img_idx, pred in enumerate(run_predictions):
            preds_per_image[img_idx].append(pred)
    
    # Estat√≠sticas por run
    per_run_iou = []
    per_run_details = []
    
    for run_idx in range(mc_runs):
        # Extrair predi√ß√µes desta run
        run_preds = [preds_per_image[i][run_idx] for i in range(n_images)]
        
        # Calcular m√©tricas desta run
        pred_flat = np.concatenate([p.ravel() for p in run_preds])
        gt_flat = np.concatenate([gt.ravel() for gt in gts_all]).ravel()
        
        # Usar TorchMetrics
        iou_metric = torchmetrics.JaccardIndex(num_classes=n_classes, average='macro', task='multiclass')
        iou_val = iou_metric(torch.tensor(pred_flat), torch.tensor(gt_flat)).item() * 100.0
        
        per_run_iou.append(iou_val)
        per_run_details.append({
            'run_idx': run_idx,
            'iou': iou_val,
            # ... outras m√©tricas
        })
    
    # Escolher melhor run
    best_run_idx = int(np.argmax(per_run_iou))
    best_run_preds = [preds_per_image[i][best_run_idx] for i in range(n_images)]
    
    return np.array(best_run_preds)
```

### 3. models.py - Arquiteturas Dispon√≠veis

**Modelos realmente implementados:**

#### FCN8s Customizada:
```python
class FCN8s(nn.Module):
    """FCN8s real implementada no projeto"""
    def __init__(self, n_class=6):
        super(FCN8s, self).__init__()
        
        # Encoder baseado em VGG (c√≥digo real)
        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)
        self.relu1_1 = nn.ReLU(inplace=True)
        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)
        self.relu1_2 = nn.ReLU(inplace=True)
        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
        
        # ... camadas intermedi√°rias
        
        # Decoder com upsampling
        self.upscore32 = nn.ConvTranspose2d(n_class, n_class, 64, stride=32)
        self.upscore_pool4 = nn.ConvTranspose2d(n_class, n_class, 4, stride=2)
        
    def forward(self, x):
        # Forward pass real implementado
        h = x
        h = self.relu1_1(self.conv1_1(h))
        h = self.relu1_2(self.conv1_2(h))
        pool1 = self.pool1(h)
        
        # ... propaga√ß√£o pelas camadas
        
        # Skip connections
        score = self.score_fr(h)
        upscore32 = self.upscore32(score)
        
        return upscore32[:, :, 31:31+x.size(2), 31:31+x.size(3)]
```

#### Factory de Modelos (Real):
```python
def build_model(model_name, params):
    """Factory real de modelos implementada"""
    
    if model_name == 'fcn8s':
        model = FCN8s(n_class=params['n_classes'])
        
    elif model_name == 'unet':
        model = smp.Unet(
            encoder_name="efficientnet-b7",
            encoder_weights="imagenet",
            in_channels=3,
            classes=params['n_classes'],
            activation=None,  # Sem ativa√ß√£o (logits)
        )
        
    elif model_name == 'deeplabv3plus':
        model = smp.DeepLabV3Plus(
            encoder_name='efficientnet-b0',
            encoder_weights="imagenet", 
            in_channels=3,
            classes=params['n_classes'],
            activation=None,
        )
    
    else:
        raise Exception(f"{model_name} -> invalid model name.")
    
    model.to(params['device'])
    return model
```

### 4. Dataset Classes - Sistema Real

#### DatasetIcmbio (dataset1.py) - Vers√£o Completa:
```python
class DatasetIcmbio(torch.utils.data.Dataset):
    """Dataset real com sliding window e data augmentation forte"""
    
    def __init__(self, data_files, label_files, edge_files=None,
                 window_size=256, stride=128, n_channels=3, 
                 cache=True, augmentation=True):
        
        # Configura√ß√£o real de sliding window
        if isinstance(window_size, tuple):
            self.window_h, self.window_w = window_size
        else:
            self.window_h = self.window_w = window_size
            
        # Cache de imagens na mem√≥ria
        self.data_cache_ = {}
        self.label_cache_ = {}
        self.edge_cache_ = {}
        
        # Calcular grid de patches por imagem
        sample = io.imread(self.data_files[0])
        H, W = sample.shape[:2]
        self.steps_h = (H - self.window_h) // self.stride_h + 1
        self.steps_w = (W - self.window_w) // self.stride_w + 1
        self.patches_per_img = self.steps_h * self.steps_w

    def __len__(self):
        """Total de patches em todo o dataset"""
        return len(self.data_files) * self.patches_per_img

    def __getitem__(self, idx):
        """Extra√ß√£o real de patch"""
        # Calcular qual imagem e qual patch
        img_idx = idx // self.patches_per_img
        patch_idx = idx % self.patches_per_img
        row = patch_idx // self.steps_w
        col = patch_idx % self.steps_w
        
        # Coordenadas do patch
        y1 = row * self.stride_h
        x1 = col * self.stride_w
        y2 = y1 + self.window_h
        x2 = x1 + self.window_w
        
        # Carregar imagem (com cache)
        if img_idx in self.data_cache_:
            data = self.data_cache_[img_idx]
        else:
            img = io.imread(self.data_files[img_idx])[:, :, :3] / 255.0
            data = img.transpose(2,0,1).astype('float32')  # CHW
            if self.cache:
                self.data_cache_[img_idx] = data
        
        # Carregar label
        if img_idx in self.label_cache_:
            label = self.label_cache_[img_idx]
        else:
            lbl_img = io.imread(self.label_files[img_idx])[:,:,:3]
            label = convert_from_color(lbl_img).astype('int64')  # Convers√£o RGB->ID
            if self.cache:
                self.label_cache_[img_idx] = label
        
        # Extrair patch
        data_p = data[:, y1:y2, x1:x2]
        label_p = label[y1:y2, x1:x2]
        
        # Data augmentation se habilitado
        if self.augmentation:
            data_p, label_p = self.data_augmentation_strong(data_p, label_p)
        
        # Converter para tensores
        return torch.from_numpy(data_p), torch.from_numpy(label_p)

    @classmethod
    def data_augmentation_strong(cls, data_p, label_p, edge_p=None, 
                               p_flip=0.5, p_mirror=0.5, p_rotate=0.5, 
                               p_color=0.5, p_noise=0.5, p_blur=0.5):
        """Data augmentation forte implementado"""
        
        img, lbl = data_p, label_p
        
        # Flips geom√©tricos
        if np.random.rand() < p_flip:
            img = img[..., ::-1]  # Vertical flip
            lbl = lbl[..., ::-1]
            
        if np.random.rand() < p_mirror:
            img = img[..., :, ::-1]  # Horizontal flip
            lbl = lbl[..., :, ::-1]
        
        # Rota√ß√µes de 90¬∞
        if np.random.rand() < p_rotate:
            k = np.random.randint(1, 4)  # 90¬∞, 180¬∞, 270¬∞
            img = np.rot90(img, k, axes=(1, 2))
            lbl = np.rot90(lbl, k, axes=(0, 1))
        
        # Color augmentation
        if np.random.rand() < p_color:
            # Brightness
            brightness = np.random.uniform(0.8, 1.2)
            img = np.clip(img * brightness, 0, 1)
            
            # Contrast
            contrast = np.random.uniform(0.8, 1.2)
            img = np.clip((img - 0.5) * contrast + 0.5, 0, 1)
        
        # Gaussian noise
        if np.random.rand() < p_noise:
            noise_std = np.random.uniform(0.01, 0.05)
            noise = np.random.normal(0, noise_std, img.shape).astype(img.dtype)
            img = np.clip(img + noise, 0, 1)
        
        # Gaussian blur
        if np.random.rand() < p_blur:
            # Implementa√ß√£o simples com OpenCV
            k = np.random.choice([3, 5, 7])
            img_np = img.transpose(1, 2, 0)  # CHW -> HWC
            img_np = cv2.GaussianBlur(img_np, (k, k), 0)
            img = img_np.transpose(2, 0, 1)  # HWC -> CHW
        
        return np.ascontiguousarray(img), np.ascontiguousarray(lbl)
```

### 5. project_utils.py - Fun√ß√µes Essenciais

#### Convers√£o RGB ‚Üî Labels (Real):
```python
def convert_from_color(arr_3d):
    """Converte imagem RGB para labels num√©ricas (fun√ß√£o real)"""
    
    # Palette oficial do projeto
    palette = {
        0: (255, 0, 0),      # Urbano - Vermelho
        1: (0, 255, 0),      # Vegeta√ß√£o Densa - Verde  
        2: (0, 0, 0),        # Sombra - Preto
        3: (255, 255, 0),    # Vegeta√ß√£o Esparsa - Amarelo
        4: (255, 165, 0),    # Agricultura - Laranja
        5: (128, 128, 128),  # Rocha - Cinza
        6: (139, 69, 19),    # Solo Exposto - Marrom
        7: (0, 0, 255),      # √Ågua - Azul
    }
    
    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)
    
    for label, color in palette.items():
        r, g, b = color
        mask = (arr_3d[..., 0] == r) & (arr_3d[..., 1] == g) & (arr_3d[..., 2] == b)
        arr_2d[mask] = label
    
    return arr_2d

def convert_to_color(arr_2d):
    """Converte labels num√©ricas para RGB (fun√ß√£o real)"""
    # Fun√ß√£o inversa para visualiza√ß√£o
    palette = {
        0: (255, 0, 0), 1: (0, 255, 0), 2: (0, 0, 0), 3: (255, 255, 0),
        4: (255, 165, 0), 5: (128, 128, 128), 6: (139, 69, 19), 7: (0, 0, 255)
    }
    
    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)
    
    for label, color in palette.items():
        arr_3d[arr_2d == label] = color
    
    return arr_3d
```

#### Sliding Window (Real):
```python
def sliding_window(img, stride=10, window_size=(20, 20)):
    """
    Gerador de sliding window real implementado
    Garante inclus√£o da borda final
    """
    H, W = img.shape[:2]
    win_h, win_w = window_size
    
    # Calcular pontos de in√≠cio incluindo borda
    x_starts = list(range(0, max(1, H - win_h + 1), stride))
    if x_starts[-1] != max(0, H - win_h):
        x_starts.append(max(0, H - win_h))
    
    y_starts = list(range(0, max(1, W - win_w + 1), stride))
    if y_starts[-1] != max(0, W - win_w):
        y_starts.append(max(0, W - win_w))
    
    # Gerar coordenadas
    for x0 in x_starts:
        for y0 in y_starts:
            yield x0, y0, win_h, win_w
```

#### Factory de Otimizadores (Real):
```python
def make_optimizer(args, net):
    """Factory de otimizadores implementada"""
    trainable = filter(lambda x: x.requires_grad, net.parameters())
    
    if args['optimizer'] == 'SGD':
        return optim.SGD(trainable, lr=args['lr'], momentum=0.9, nesterov=True)
        
    elif args['optimizer'] == 'ADAM':
        return optim.Adam(trainable, 
                         lr=args['lr'],
                         betas=(args['beta1'], args['beta2']),
                         eps=args['epsilon'],
                         weight_decay=args['weight_decay'])
                         
    elif args['optimizer'] == 'RADAM':
        return optim.RAdam(trainable,
                          lr=args['lr'],
                          betas=(args['beta1'], args['beta2']),
                          eps=args['epsilon'],
                          weight_decay=args['weight_decay'],
                          decoupled_weight_decay=True)
                          
    elif args['optimizer'] == 'ADAMW':
        return optim.AdamW(trainable,
                          lr=args['lr'],
                          betas=(args['beta1'], args['beta2']),
                          eps=args['epsilon'],
                          weight_decay=args['weight_decay'])
    
    # ... outros otimizadores implementados
```

#### Sistema de M√©tricas (Real):
```python
def metrics(predictions, gts, label_values, all=False, filepath=None):
    """Sistema de m√©tricas real implementado no projeto"""
    
    # Matriz de confus√£o
    cm = confusion_matrix(gts, predictions, labels=range(len(label_values)))
    
    # Plotar matriz de confus√£o
    from mlxtend.plotting import plot_confusion_matrix
    fig, ax = plot_confusion_matrix(conf_mat=cm * 100,
                                    colorbar=True,
                                    show_absolute=False,
                                    show_normed=True,
                                    class_names=label_values)
    fig.savefig(f"./{filepath}/cm_all" if all else f'./{filepath}/cm', 
                dpi=fig.dpi, bbox_inches='tight')
    plt.close(fig)
    
    # Calcular m√©tricas
    total = sum(sum(cm))
    accuracy = sum([cm[x][x] for x in range(len(cm))]) * 100 / float(total)
    
    # F1 Score por classe
    F1Score = np.zeros(len(label_values))
    for i in range(len(label_values)):
        try:
            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))
        except:
            pass  # Classe n√£o presente no conjunto
    
    # Relat√≥rio em arquivo
    txt = []
    txt.append("Confusion Matrix")
    txt.append(str(cm))
    txt.append(f"Total pixels processed: {total}")
    txt.append(f"Total accuracy: {accuracy}%")
    txt.append("F1Score per class:")
    for l_id, score in enumerate(F1Score):
        txt.append(f"{label_values[l_id]}: {score}")
    txt.append(f"mean F1Score: {100.0*np.mean(F1Score)}")
    
    # Salvar relat√≥rio
    with open(f"{filepath}/metrics_test.txt", "w") as f:
        for line in txt:
            f.write(str(line) + "\n")
    
    return accuracy
```

### 6. Sistema de Early Stopping (Real)

#### Classe Callback Implementada:
```python
class Callback():
    """Sistema real de early stopping implementado em main.py"""
    
    def __init__(self, patience=10, min_value=66):
        self.PATIENCE = patience
        self.COUNTER = 0
        self.MIN_LIMIT = min_value
        self.BEST_VALUE = 0
        self.BEST_TRAINER = []

    def patience_iou_val(self, iou):
        """Crit√©rio baseado no IoU de valida√ß√£o (usado no projeto)"""
        if iou > self.MIN_LIMIT and iou > self.BEST_VALUE:
            self.BEST_VALUE = iou
            self.BEST_TRAINER = trainer
            self.COUNTER = 0
            print(f"PATIENCE ::: New best epoch | Saving model...")
            return True  # Salva modelo
        elif self.BEST_VALUE <= self.MIN_LIMIT:
            print(f"PATIENCE :::: Val mIoU < {self.MIN_LIMIT} % | Skipping save...")
            return False
        else:
            self.COUNTER += 1
            print(f"PATIENCE ::: Waiting for {self.COUNTER} epoch(s) | Skipping save...")
            return False
    
    # Outros crit√©rios implementados:
    def patience_acc_val(self, avg_acc):
        """Baseado na acur√°cia de valida√ß√£o"""
        # Implementa√ß√£o similar...
    
    def patience_f1_val(self, f1):
        """Baseado no F1-score de valida√ß√£o"""
        # Implementa√ß√£o similar...
```

### 7. common.py - Transformadas Wavelet

#### DWT/IWT Implementadas:
```python
def dwt_init(x):
    """Discrete Wavelet Transform real implementada"""
    x01 = x[:, :, 0::2, :] / 2
    x02 = x[:, :, 1::2, :] / 2
    x1 = x01[:, :, :, 0::2]
    x2 = x02[:, :, :, 0::2]
    x3 = x01[:, :, :, 1::2]
    x4 = x02[:, :, :, 1::2]
    
    x_LL = x1 + x2 + x3 + x4  # Low-Low
    x_HL = -x1 - x2 + x3 + x4  # High-Low
    x_LH = -x1 + x2 - x3 + x4  # Low-High
    x_HH = x1 - x2 - x3 + x4   # High-High
    
    return torch.cat((x_LL, x_HL, x_LH, x_HH), 1)

class DWT(nn.Module):
    """M√≥dulo DWT real usado em modelos avan√ßados"""
    def __init__(self):
        super(DWT, self).__init__()
        self.requires_grad = False

    def forward(self, x):
        return dwt_init(x)

class IWT(nn.Module):
    """Inverse Wavelet Transform real"""
    def __init__(self):
        super(IWT, self).__init__()
        self.requires_grad = False

    def forward(self, x):
        return iwt_init(x)
```

### 8. focal_loss.py - Loss Functions Avan√ßadas

#### Focal Loss Real:
```python
def focal_loss(labels, logits, alpha, gamma):
    """Focal Loss implementada no projeto"""
    BCLoss = F.binary_cross_entropy_with_logits(input=logits, target=labels, reduction="none")
    
    if gamma == 0.0:
        modulator = 1.0
    else:
        modulator = torch.exp(-gamma * labels * logits - gamma * torch.log(1 + 
            torch.exp(-1.0 * logits)))
    
    loss = modulator * BCLoss
    weighted_loss = alpha * loss
    focal_loss = torch.sum(weighted_loss)
    focal_loss /= torch.sum(labels)
    
    return focal_loss

def FocalLoss(labels, logits, samples_per_cls, no_of_classes, beta, gamma):
    """Class-Balanced Focal Loss implementada"""
    effective_num = 1.0 - np.power(beta, samples_per_cls)
    weights = (1.0 - beta) / np.array(effective_num)
    weights = weights / np.sum(weights) * no_of_classes
    
    labels_one_hot = F.one_hot(labels, no_of_classes).float()
    
    weights = torch.tensor(weights).float()
    weights = weights.unsqueeze(0)
    weights = weights.repeat(labels_one_hot.shape[0], 1) * labels_one_hot
    weights = weights.sum(1).unsqueeze(1).repeat(1, no_of_classes)
    
    cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)
    return cb_loss
```

### 9. inference.py - Script de Produ√ß√£o

#### Infer√™ncia Real para Imagens Grandes:
```python
# Configura√ß√£o real do script
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Usando dispositivo: {device}")

# Caminhos reais configurados
input_dir = '../../dataset_35/images'
dir_path = '20250720K4_b75_drop_Plato_flipRotColor_unet_focal_loss_RADAM'
model_path = f'output_35/{dir_path}/best_epoch.pth.tar'
output_dir = f'output_35/{dir_path}/inference_val'
selected_files_path = 'folds/fold1_images.txt'

# Modelo com Dropout para MC sampling
class UNetWithDropout(smp.Unet):
    """Classe real implementada para MC Dropout"""
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        for i, block in enumerate(self.decoder.blocks):
            block.dropout = nn.Dropout2d(p=0.3)

    def forward(self, x):
        return super().forward(x)

# Carregamento real do modelo
model = UNetWithDropout(
    encoder_name='efficientnet-b7',
    in_channels=3,
    classes=8,
    activation=None,
    decoder_use_norm=True,
    decoder_interpolation="nearest"
)

# Carregamento seguro de checkpoint
with torch.serialization.safe_globals([torch._utils._rebuild_tensor_v2]):
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)

checkpoint_state = checkpoint.get('model_state_dict') or checkpoint.get('state_dict') or checkpoint
model.load_state_dict(checkpoint_state, strict=False)
model = model.to(device)
model.eval()

# Fun√ß√£o de sliding window real
def sliding_window(img, window_size=(224, 224), stride=224):
    """Sliding window implementado para infer√™ncia"""
    H, W = img.shape[:2]
    h, w = window_size
    
    for y in range(0, H - h + 1, stride):
        for x in range(0, W - w + 1, stride):
            yield y, x, h, w
    
    # Bordas finais
    if H % stride != 0:
        y = H - h
        for x in range(0, W - w + 1, stride):
            yield y, x, h, w
    
    if W % stride != 0:
        x = W - w
        for y in range(0, H - h + 1, stride):
            yield y, x, h, w
```

## Sistema de Arquivos Real

### Estrutura de Sa√≠da:
```
output_35/
‚îî‚îÄ‚îÄ [nome_do_experimento]/
    ‚îú‚îÄ‚îÄ best_epoch.pth.tar       # ‚úÖ Melhor modelo salvo automaticamente
    ‚îú‚îÄ‚îÄ metrics_train.npz        # ‚úÖ M√©tricas de treinamento
    ‚îú‚îÄ‚îÄ test_result.npz         # ‚úÖ Resultados do teste (se executado)
    ‚îú‚îÄ‚îÄ metrics_all_in_one.png  # ‚úÖ Gr√°ficos de m√©tricas
    ‚îú‚îÄ‚îÄ cm.png                  # ‚úÖ Matriz de confus√£o
    ‚îî‚îÄ‚îÄ inference_val/          # ‚úÖ Resultados de infer√™ncia
        ‚îî‚îÄ‚îÄ [imagens_processadas].png
```

### Folds do Dataset (Real):
```
folds/
‚îú‚îÄ‚îÄ fold1_images.txt    # ‚úÖ Treino (junto com fold2 e fold3)
‚îú‚îÄ‚îÄ fold1_labels.txt
‚îú‚îÄ‚îÄ fold2_images.txt    # ‚úÖ Treino
‚îú‚îÄ‚îÄ fold2_labels.txt
‚îú‚îÄ‚îÄ fold3_images.txt    # ‚úÖ Treino  
‚îú‚îÄ‚îÄ fold3_labels.txt
‚îú‚îÄ‚îÄ fold4_images.txt    # ‚úÖ Valida√ß√£o
‚îú‚îÄ‚îÄ fold4_labels.txt
‚îú‚îÄ‚îÄ fold5_images.txt    # ‚úÖ Teste
‚îî‚îÄ‚îÄ fold5_labels.txt
```

## Configura√ß√µes Reais do Projeto

### Par√¢metros Hardcoded em main.py:
```python
# Configura√ß√£o real atual no c√≥digo
params = {
    'root_dir': '../../dataset_35/',
    'cache': True,                    # Cache de imagens na RAM
    'window_size': (224, 224),       # Tamanho das patches
    'bs': 40,                        # Batch size
    'n_classes': 8,                  # N√∫mero de classes
    'classes': [                     # Nomes das classes
        "Urbano", "Vegeta√ß√£o Densa", "Sombra", "Vegeta√ß√£o Esparsa", 
        "Agricultura", "Rocha", "Solo Exposto", "√Ågua"
    ],
    'maximum_epochs': 999,           # M√°ximo de √©pocas
    'save_epoch': 2,                 # Salvar a cada N √©pocas
    'print_each': 100,               # Print de progresso
    'augment': False,                # Data augmentation (configur√°vel)
    'cpu': None,                     # Usar GPU
    'device': 'cuda',
    'precision': 'full',             # Precis√£o completa

    # Otimizador
    'optimizer_params': {
        'optimizer': 'ADAM',
        'lr': 1e-3,
        'beta1': 0.9,
        'beta2': 0.999,
        'weight_decay': 0,
        'epsilon': 1e-8,
        'momentum': 0.9
    },
    
    # Learning Rate Scheduler
    'lrs_params': {
        'type': 'Plateau',           # ReduceLROnPlateau
        'lr_decay': 30,
        'milestones': [25, 35, 45],
        'gamma': 0.1
    },
    
    # Loss Function
    'loss': {
        'name': LossFN.TVERSKY,      # Tversky Loss
        'params': {
            'weights': 'calculate',   # Pesos calculados automaticamente
            'alpha': 0.5,            # Para Focal Loss
            'gamma': 2.0,            # Para Focal Loss
            'beta': 0.5,             # Para Tversky Loss
        }
    },
    
    # Early Stopping
    'patience': 10,                  # Paci√™ncia para early stopping
    'stride': 64,                    # Stride para valida√ß√£o
}
```

### Loss Functions Dispon√≠veis (Enum Real):
```python
class LossFN:
    CROSS_ENTROPY = 'cross_entropy'
    FOCAL_LOSS = 'focal_loss'
    DICE = 'DICE'
    JACCARD = 'JACCARD'
    TVERSKY = 'TVERSKY'              # Padr√£o atual
```

### Modelos Dispon√≠veis:
```python
class ModelChooser:
    SEGNET_MODIFICADA = 'segnet_modificada'  # FCN8s customizada
    UNET = 'unet'                            # U-Net com EfficientNet-B7
    DEEPLABV3PLUS = 'deeplabv3plus'          # DeepLabV3+ 
    # Outros modelos podem ser adicionados no build_model()
```

## Como Executar - Passo Real

### 1. Prepara√ß√£o dos Dados
```bash
# Estrutura necess√°ria (real)
dataset_35/
‚îú‚îÄ‚îÄ images/          # Suas imagens RGB
‚îú‚îÄ‚îÄ labels/          # Labels RGB com cores espec√≠ficas
‚îî‚îÄ‚îÄ folds/           # Arquivos de divis√£o K-fold
    ‚îú‚îÄ‚îÄ fold1_images.txt    # Lista de nomes de arquivo
    ‚îú‚îÄ‚îÄ fold1_labels.txt    # Mesmos nomes
    ‚îî‚îÄ‚îÄ ... (fold2-5)

# Formato dos arquivos fold (exemplo real):
# fold1_images.txt:
image001.png
image002.png
image003.png

# fold1_labels.txt:
image001.png
image002.png  
image003.png
```

### 2. Instala√ß√£o Real
```bash
# Depend√™ncias m√≠nimas necess√°rias
pip install torch torchvision
pip install segmentation-models-pytorch
pip install albumentations
pip install scikit-image opencv-python
pip install matplotlib tqdm pandas
pip install torchmetrics
pip install mlxtend  # Para plot_confusion_matrix

# Verificar CUDA
python -c "import torch; print(torch.cuda.is_available())"
```

### 3. Configura√ß√£o
```python
# Editar main.py - ajustar estes par√¢metros para seu caso:

# 1. OBRIGAT√ìRIO - Caminho dos dados
params['root_dir'] = 'caminho/para/seus/dados/'

# 2. OBRIGAT√ìRIO - Suas classes (se diferentes)
params['classes'] = ["Sua_Classe_0", "Sua_Classe_1", ...]
params['n_classes'] = len(params['classes'])

# 3. RECOMENDADO - Ajustar para sua GPU
params['bs'] = 16  # Reduzir se GPU pequena
params['cache'] = False  # Desabilitar se pouca RAM

# 4. OPCIONAL - Outras configura√ß√µes
params['augment'] = True   # Ativar data augmentation
params['patience'] = 5     # Early stopping mais agressivo
```

### 4. Execu√ß√£o Real
```bash
# Treinamento b√°sico
python main.py

# Durante execu√ß√£o, voc√™ ver√° (real):
# - Progress bar com m√©tricas em tempo real
# - Gr√°ficos salvos automaticamente
# - Checkpoints autom√°ticos do melhor modelo
# - Early stopping quando parar de melhorar

# Exemplo de sa√≠da real:
# Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1234/1234 [12:34<00:00, 1.23it/s, 
#           Epoch=15, Acc=78.5, F1=76.2, MCC=74.8, IoU=71.3, Loss=0.234]
# PATIENCE ::: New best epoch | Saving model...
```

### 5. Resultados Reais
```bash
# Ap√≥s treinamento, arquivos gerados automaticamente:
ls output_35/[seu_experimento]/
# best_epoch.pth.tar         # Melhor modelo
# metrics_train.npz           # M√©tricas salvas
# metrics_all_in_one.png      # Gr√°ficos
# cm.png                      # Matriz de confus√£o

# Testar modelo treinado
python inference.py  # Usar o checkpoint salvo

# Ver m√©tricas detalhadas
python -c "
import numpy as np
data = np.load('output_35/[experimento]/metrics_train.npz')
print(f'Melhor IoU: {max(data[\"iou_val\"]):.2f}%')
print(f'√âpocas treinadas: {len(data[\"iou_val\"])}')
"
```

## Scripts Auxiliares Reais

### extra/test_trained.py
```python
# Script real para an√°lise detalhada de resultados
class TestTrained:
    def __init__(self, test_result_path: str, classes, name: str):
        self.test = np.load(test_result_path, allow_pickle=True)
        self.classes = classes
        self.name = name
        
        self.y_pred = self.test.f.arr_0.item().get('all_preds')
        self.y_true = self.test.f.arr_0.item().get('all_gts')

    def generate_report(self):
        # M√©tricas por classe
        y_true_ = torch.tensor(self.y_true.ravel())
        y_pred_ = torch.tensor(self.y_pred.ravel())
        
        # Calcular m√©tricas
        acc = accuracy(y_true_, y_pred_)
        jaccard = MulticlassJaccardIndex(task="multiclass", num_classes=len(self.classes), average='macro')
        jac = jaccard(y_true_, y_pred_)
        kap = cohen_kappa_score(y_true_, y_pred_)
        
        print(f'Accuracy: {acc}\t IoU: {jac}\t Kappa: {kap}')
        
        # Relat√≥rio detalhado
        report = classification_report(y_true_, y_pred_, target_names=self.classes)
        print(f'Relat√≥rio:\n{report}')
```

### extra/label_change_pixel_color.py
```python
# Script real para trocar cores dos labels
class LabelChangePixelColor:
    def run(self, original_color, new_color):
        """Troca cor espec√≠fica em todas as imagens de label"""
        for img_path in self.label_files:
            img = cv2.imread(img_path)
            
            # Criar m√°scara para cor original
            mask = np.all(img == original_color, axis=2)
            
            # Aplicar nova cor
            img[mask] = new_color
            
            # Salvar
            cv2.imwrite(output_path, img)

# Uso real:
# python extra/label_change_pixel_color.py --label_dir=dataset_35/labels --ori_color="(0,255,197)" --new_color="(255,0,0)"
```

## Limita√ß√µes e Considera√ß√µes Reais

### O que o Projeto N√ÉO tem (atualmente):
- ‚ùå Interface gr√°fica
- ‚ùå Configura√ß√£o por arquivo (.yaml/.json)
- ‚ùå Scripts de setup autom√°tico
- ‚ùå Docker containeriza√ß√£o
- ‚ùå Logging estruturado
- ‚ùå Tensorboard integration
- ‚ùå Hyperparameter tuning autom√°tico

### O que Funciona Muito Bem:
- ‚úÖ Treinamento robusto com early stopping
- ‚úÖ Multiple loss functions (Tversky, Focal, Dice, etc.)
- ‚úÖ Data augmentation configur√°vel e forte
- ‚úÖ Monte Carlo Dropout para incerteza
- ‚úÖ Sliding window para imagens grandes
- ‚úÖ Cache inteligente de dados
- ‚úÖ M√©tricas completas (IoU, F1, MCC, Accuracy)
- ‚úÖ Visualiza√ß√µes autom√°ticas
- ‚úÖ Sistema de checkpoints
- ‚úÖ K-fold cross validation

## Resumo do que Voc√™ Pode Fazer Agora

### Imediatamente (c√≥digo existente):
1. **Treinar modelo**: `python main.py`
2. **Fazer infer√™ncia**: `python inference.py`
3. **Analisar resultados**: usar scripts em `extra/`
4. **Ajustar par√¢metros**: editar `main.py`
5. **Usar diferentes modelos**: mudar `params['model']['name']`
6. **Experimentar loss functions**: mudar `params['loss']['name']`

### Modifica√ß√µes Simples:
1. **Suas classes**: editar `params['classes']` e `convert_from_color()`
2. **Seu dataset**: ajustar `params['root_dir']` e criar folds
3. **Sua GPU**: ajustar `params['bs']` e `params['cache']`
4. **Data augmentation**: `params['augment'] = True/False`

Este projeto j√° √© **muito completo e funcional** para segmenta√ß√£o sem√¢ntica profissional. Ele implementa as melhores pr√°ticas de deep learning e est√° pronto para uso em cen√°rios reais de classifica√ß√£o de uso do solo! üéØ
